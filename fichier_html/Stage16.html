<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <title> Internshiplz - Yuhe TANG - Qinyue LIU - M1 IDL </title>
    <link rel="stylesheet" type="text/css" media="all" href="../FichierHtml_style.css" />
</head>

<body><p>Titre: Création de corpus multilingue et de lexiques terminologiques par apprentissage automatique</p><p>Date: 2022-01-24</p><p>Organisme: LIASD</p><p>Lieu: Saint Denis</p><br/><p>OFFRE DE STAGE DE MASTER OU D’INGENIEUR</p><p></p><p>Création de corpus multilingue et de lexiques terminologiques par apprentissage automatique</p><p></p><p>Durée du stage : 5/6 mois (début : Février/Mars 2022)</p><p></p><p>Gratification : montant légal en vigueur (environ 600€ / mois).</p><p></p><p>Laboratoire d’accueil :</p><p></p><p>Equipe PASTIS du LIASD (EA 4383), Université Paris 8, 2 rue de la liberté, 93526 Saint Denis</p><p></p><p></p><p>Sujet de stage</p><p></p><p>La collecte de données textuelles issues du web a donné lieu à de nombreuses approches d'extraction de données pour résoudre des problèmes spécifiques opérant dans des domaines ad-hoc. Nous nous intéressons à la création d'un corpus multilingue construit à partir de textes issus d'entreprises regroupées par catégories (27 catégories au total).</p><p></p><p>Partant d'un corpus monolingue définissant les relations entre textes, entreprises et catégories, pour un ensemble de catégories prédéfinies, une première étape d'apprentissage supervisé permet de définir un modèle de ces relations. Par combinaison d'un crawler et d'un scraper, une seconde étape d'apprentissage non supervisé permet d'étendre le corpus et ses relations inhérentes à des relations multilingues. La seconde étape, traitant de nouvelles données utilise un scraper et un crawler existants.</p><p></p><p>L'objectif de ce stage est d'adapter ces deux outils afin de créer un modèle adapté aux spécificités multilingues contenues dans les textes pris sur le web et d’enrichir le lexique spécialisé par apprentissage.</p><p></p><p></p><p></p><p>Le stage comportera les étapes suivantes (la réutilisabilité des ressources et les codes produits, feront l'objet d'une documentation tout au long du stage) :</p><p></p><p>-   Création corpus multilingue (enrichissement dataset existant)</p><p></p><p>Pour l'apprentissage supervisé comme non supervisé, il s'agit principalement de définir les bons paramètres d'approches classiques (Random forests, Gradient boosting machines, Convolutionnal networks) avec les corpus actuels et les données disponibles.</p><p></p><p>Par la suite nous allons procéder à :</p><p></p><p>-   la mise en place d’un modèle basé sur BERT et CamemBERT</p><p>    (l'annotation des termes spécifiques sera fondée sur l’analyse des</p><p>    co-occurrences de termes désignant l'ensemble des mots-clés de</p><p>    départ, à l’aide de vecteurs de plongement fournis par ces</p><p>    modèles) ;</p><p></p><p>-   le ré-entraînement de ces modèles, l’utilisation des vecteurs de</p><p>    plongement et les métriques développées pour le comparatif entre</p><p>    les termes trouvés par des modèles utilisés avec annotations des</p><p>    mots-clés et sacs de mots afin de valider les spécificités</p><p>    utilisées sur le corpus multilingue;</p><p></p><p>-   validation des approches sur la création du lexique terminologique</p><p>    du corpus multilingue par comparaison avec celui du corpus</p><p>    monolingue établi par analyse statistique (n-grams et tf-idf);</p><p></p><p>-   rédaction du rapport de stage, et mise en forme des ressources et</p><p>    codes produits.</p><p></p><p></p><p>Compétences particulières et formation requise</p><p></p><p>Ce stage s'adresse aux étudiant.e.s de master 2 en Informatique et/ou</p><p>Analyse de données ou en TAL</p><p></p><p>-   Compétences en programmation Python (Numpy, Scipy, Pandas,</p><p>    Scikit-learn, Keras).</p><p></p><p>-   Outils de TAL (outils fondés sur l’apprentissage, modèles de</p><p>    langue, classifieurs, si possible outils statistiques de</p><p>    lexicométrie).</p><p></p><p>-   Curiosité et volonté de tester de nouvelles méthodes.</p><p></p><p>Candidature</p><p></p><p>L'étudiant-e sera accueilli-e dans les locaux de l’Université</p><p>Paris 8 au laboratoire LIASD.</p><p></p><p></p><p>Contact :</p><p></p><p>Revekka Kyriakoglou, LIASD, équipe PASTIS, UP8, kyriakoglou@up8.edu</p><p>Anna Pappa, LIASD, équipe PASTIS, UP8, ap@up8.edu</p><p></p><p></p><p>References</p><p></p><p>[1] George D. Greenwade. The Comprehensive Tex Archive Network (CTAN).</p><p>TUGBoat, 14(3):342–351, 1993.</p><p></p><p>[2] Emilio Ferrara, Pasquale De Meo, Giacomo Fiumara, and Robert</p><p>Baumgartner. Web data extraction,applications and techniques: A survey.</p><p>Knowledge-Based Systems, 70:301–323, 2014.</p><p></p><p>[3] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion</p><p>Jones, Aidan N Gomez, Lukasz Kaiser,and Illia Polosukhin. Attention is all you need. InAdvances in neural information processing systems, pages5998–6008, 2017.</p><p></p><p>[4] Mahtab Ahmed, Chahna Dixit, Robert E Mercer, Atif Khan, Muhammad</p><p>Rifayat Samee, and Felipe Urra.Multilingual corpus creation for multilingual semantic similarity task. InProceedings of the 12th</p><p>LanguageResources and Evaluation Conference, pages 4190–4196, 2020.</p><p></p><p>[5] Qing Xie, Xinyuan Zhang, Ying Ding, and Min Song. Monolingual and multilingual topic analysis using ldaand bert embeddings.Journal of</p><p>Informetrics, 14(3):101055, 2020.</p><p></p><p>[6] Boshko Koloski, Senja Pollak, BlaˇzˇSkrlj, and Matej Martinc.</p><p>Extending neural keyword extraction withtf-idf tagset matching.arXiv preprint arXiv:2102.00472, 2021.</p><p></p><p>[7] Jakub Piskorski, Nicolas Stefanovitch, Guillaume Jacquet, and Aldo</p><p>Podavini. Exploring linguistically-lightweight keyword extraction techniques for indexing news articles in a multilingual set-up.</p><p>InProceedingsof the EACL Hackashop on News Media Content Analysis and</p><p>Automated Report Generation, pages 35–44,2021.</p><p></p><p>[8] Ao Xiong, Derong Liu, Hongkang Tian, Zhengyuan Liu, Peng Yu, and</p><p>Michel Kadoch. News keywordextraction algorithm based on semantic clustering and word graph model.Tsinghua Science and Technology, 26(6):886–893, 2021</p><p></p>
</body>
</html>
        