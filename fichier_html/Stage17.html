<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <title> Internshiplz - Yuhe TANG - Qinyue LIU - M1 IDL </title>
    <link rel="stylesheet" type="text/css" media="all" href="../FichierHtml_style.css" />
</head>

<body><p>Titre: Finalisation et évaluation de la version libtorch native de LIMA</p><p>Date: 2022-01-20</p><p>Organisme: CEA</p><p>Lieu: Palaiseau</p><br/><p></p><p>Le laboratoire LASTI a développé l'analyseur linguistique multilingue libre LIMA [1].</p><p></p><p>Des modules d'analyse à base de réseaux de neurones fondés sur</p><p>TensorFlow ont été développés permettant d'obtenir une qualité d'analyse au niveau de l'état de l'art [3] sur les plus de 65 langues du projet Universal Dependencies [4].</p><p></p><p>Cette implémentation fondée sur TensorFlow présente quelques défauts (maintenance difficile, vitesse d'analyse insuffisante). Une réimplémentation des modules deep learning a été initiée. Cette réimplémentation C++ native utilise les bibliothèque libtorch et</p><p>Eigen3. Elle présente une qualité actuellement supérieure à l'état de l'art avec des vitesses plus élevées. Mais quelques modules doivent être complétés pour obtenir une version incluant toutes les fonctionnalités précédentes.</p><p></p><p>L'objectif de ce stage consiste à participer à la complétion des modules (lemmatisation, entités nommées, analyse syntaxique) et à la mise au point des meilleurs paramètres.</p><p></p><p></p><p>Durée du contrat (en mois) : 5-6</p><p></p><p>Le travail du/de la stagiaire consistera à :</p><p>-   se familiariser avec LIMA Deep, son fonctionnement, son</p><p>    entraînement et son évaluation ;</p><p>-   participer à la fin du développement des modules ;</p><p>-   entraîner les modules d'analyse et optimiser les paramètres sur le</p><p>    cluster FactoryIA [5] du CEA ;</p><p>-   évaluer la vitesse et la qualité d'analyse de LIMA par rapport aux</p><p>    systèmes concurrents (Spacy, Stanza,...) ;</p><p></p><p>Moyens / Méthodes / Logiciels</p><p>Expertise linguistique, analyseur linguistique, superordinateur, C++,</p><p>Python, bash, linux</p><p></p><p>Profil du/de la candidat·e: Étudiant·e en informatique de niveau Bac+5, avec des connaissances en</p><p>IA (deep learning et TAL) et une bonne maîtrise du C++ sous Linux.</p><p></p><p>Localisation du poste</p><p>Nano Innov, CEA, Université Paris-Saclay,</p><p>Palaiseau, France, Ile-de-France.</p><p></p><p>Contact:</p><p>Gaël de Chalendar (gael.de-chalendar@cea.fr) https://www.emploi.cea.fr/offre-de-emploi/emploi-finalisation-et-evaluation-de-la-version-libtorch-native-de-deep-lima-h-f_19575.aspx</p><p></p><p></p><p></p><p>[1] R. Besançon, G. de Chalendar, O. Ferret, F. Gara, M. Laib,</p><p>    O. Mesnard, and N. Semmar. 2010. Lima: A multilingual framework for</p><p>    linguistic analysis and linguistic resources development and</p><p>    evaluation. In Proceedings of LREC, Malta.</p><p>[2] https://github.com/aymara/lima/wiki [3] V. Bocharov and Gaël de Chalendar. 2020. The Russian language</p><p>    pipeline in the LIMA multilingual analyzer. In Proceedings of the</p><p>    Computational Linguistics and Intellectual Technologies:</p><p>    Proceedings of the International Conference "Dialogue 2020".</p><p>[4] Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav</p><p>    Goldberg, Jan Haji, Christopher D. Manning, Ryan McDonald, Slav</p><p>    Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel</p><p>    Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank</p><p>    Collection. In Proceedings of LREC.</p><p>[5] https://www.hpcg-benchmark.org/custom/index.html?lid=155&slid=310</p><p></p><p></p>
</body>
</html>
        