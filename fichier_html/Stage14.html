<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <title> Internshiplz - Yuhe TANG - Qinyue LIU - M1 IDL </title>
    <link rel="stylesheet" type="text/css" media="all" href="../FichierHtml_style.css" />
</head>

<body><p>Titre: Adaptation au domaine en traduction neuronale</p><p>Date: 2022-02-03</p><p>Organisme: CEA LIST</p><p>Lieu: Palaiseau</p><br/><p>Titre de stage: Adaptation au domaine en traduction neuronale</p><p></p><p>Lieu du stage: CEA Saclay Nano-INNOV, Laboratoire Analyse Sémantique</p><p>Texte et Image (LASTI), 8 Avenue de la Vauve, 91120 Palaiseau</p><p></p><p>Encadrant: Nasredine Semmar, CEA LIST, Laboratoire Analyse Sémantique</p><p>Texte et Image (LASTI)</p><p></p><p></p><p>Le Laboratoire d'Analyse Sémantique des Textes et des Images (LASTI) est une équipe de 25 personnes (chercheurs, ingénieurs, doctorants) menant des travaux de recherche sur les technologies de description et de compréhension du contenu multimédia (image, texte, parole) et des documents multilingues, en particulier à grande échelle. Les enjeux scientifiques sont:</p><p>-   développer des algorithmes efficaces et robustes pour l'analyse et</p><p>    l'extraction de contenu multimédia, leur classification et analyse</p><p>    sémantique;</p><p>-   reconstitution ou fusion de données hétérogènes pour interpréter</p><p>    des scènes ou documents;</p><p>-   développer des méthodes et des outils pour la construction, la</p><p>    formalisation et l'organisation des ressources et connaissances</p><p>    nécessaires au fonctionnement de ces algorithmes;</p><p>-   intégrer plusieurs de ces briques technologiques afin d'accéder à</p><p>    l'information et répondre à un besoin utilisateur (moteurs de</p><p>    recherche, chatbot, rapports synthétiques de veille).</p><p></p><p>Contexte :</p><p></p><p>L'adaptation au domaine en traduction automatique est devenu un axe de recherche important en Traitement Automatique des Langues (TAL) et en apprentissage profond. Cet axe de recherche englobe généralement l'adaptation de la terminologie et du style de la rédaction. Au cours des dernières années, plusieurs approches ont été explorées pour adapter des modèles de traduction automatique statistique construits pour un domaine source pour lequel existe une quantité suffisante de données d'apprentissage vers un domaine cible pour lequel peu de données sont disponibles (Lewis et al., 2010; Pecina et al., 2011; Wang et al., 2012). L'approche la plus étudiée est celle qui explore l'utilisation des lexiques bilingues spécialisés. La plupart des travaux fondés sur cette approche consistent, soit à ajouter au corpus d'apprentissage un lexique bilingue ou un corpus parallèle du domaine de spécialité, soit à étendre les tables de traduction du modèle statistique en leur incorporant les entrées du lexique spécialisé (Langlais, 2002; Bouamor et al., 2012; Semmar et al., 2017). En comparaison avec la traduction statistique, peu de travaux ont été réalisés pour intégrer des lexiques bilingues dans des systèmes de traduction utilisant des modèles neuronaux pour leur adaptation au domaine (Wang et al., 2017; Duan et al., 2019; Nag et al., 2019; Hu et al., 2019), et ceci même si, plusieurs études récentes ont abordé l'adaptation au domaine en traduction neuronale (Chu et al., 2020).</p><p>Cette adaptation au domaine peut être appliquée à trois différents niveaux : en amont, en cours ou en aval de la phase d'apprentissage (Servan et al., 2017).</p><p></p><p></p><p>Sujet de stage:</p><p></p><p>L'objectif de ce stage est d'explorer et d'expérimenter les différentes approches pour l'adaptation au domaine en traduction neuronale.</p><p>L'approche qui consiste à intégrer des lexiques bilingues spécialisés dans un modèle de traduction factorisé sera privilégiée.</p><p></p><p></p><p>Le stage se déroulera selon les étapes suivantes:</p><p></p><p>-   Recherche bibliographique sur les approches d'adaptation au domaine</p><p>    des modèles factorisés pour la traduction neuronale.</p><p></p><p>-   Etude et adaptation du moteur de traduction OpenNMT</p><p>    (http://fr.opennmt.net/) pour la prise en compte de traits</p><p>    morpho-syntaxiques (Partie de discours, genre, nombre, etc.) lors</p><p>    du processus de génération des traductions.</p><p></p><p>-   Spécification et implémentation d'un modèle pour l'intégration dans</p><p>    le système OpenNMT d'un lexique bilingue spécialisé.</p><p></p><p>-   Evaluation de l'impact de ce lexique sur la qualité de traduction</p><p>    du système OpenNMT.</p><p></p><p></p><p>Les expérimentations concerneront de préférence le couple de langues anglais-français et un domaine de spécialité pour lequel un lexique bilingue est disponible.</p><p></p><p>Mots-clés :</p><p>Traitement automatique des langues, traduction automatique, adaptation au domaine, extraction terminologique, lexique bilingue spécialisé, réseaux de neurones.</p><p></p><p>Références:</p><p>-   Lewis W. D., Wendt C., Bullock D. Achieving Domain Specificity in</p><p>    SMT without Overt Siloing. Proceedings of the seventh international</p><p>    conference on Language Resources and Evaluation, 2010.</p><p>-   Pecina P., Toral A., Way A., Papavassiliou V., Prokopidis P.,</p><p>    Giagkou M. Towards Using Web-Crawled Data for Domain Adaptation in</p><p>    Statistical Machine Translation, 2011. Proceedings of the 15th</p><p>    Conference of the European Association for Machine Translation.</p><p>-   Wang W., Macherey K., Macherey W., Och F., Xu P. Improved Domain</p><p>    Adaptation for Statistical Machine Translation. Proceedings of the</p><p>    Conference of the North American Chapter of  the Association for</p><p>    Computational Linguistics: Human Language Technologies, 2012.</p><p>-   Langlais P. Improving a general-purpose statistical translation</p><p>    engine by terminological lexicons. Proceedings of the 2nd</p><p>    International Workshop on Computational Terminology</p><p>    (COMPUTERM-2002), 2002.</p><p>-   Bouamor D., Semmar N.,  Zweignebaum P. Identifying bilingual</p><p>    Multi-Word Expressions for Statistical Machine Translation.</p><p>    Proceedings of LREC 2012.</p><p>-   Semmar N., Zennaki O., Laib M. Improving the Performance of an</p><p>    Example-Based Machine Translation System Using a Domain-specific</p><p>    Bilingual Lexicon.  Proceedings of  the 29th Pacific Asia</p><p>    Conference on Language, Information and Computation, Shanghai,</p><p>    China, 2015.</p><p>-   Wang X., Tu Z., Xiong D., Zhang M. Translating Phrases in Neural</p><p>    Machine Translation. Actes de EMNLP 2017.</p><p>-   Duan X., Ji B., Jia H., Tan M., Zhang M., Chen B., Luo W., Zhang Y.</p><p>    Bilingual Dictionary Based Neural Machine Translation without Using</p><p>    Parallel Sentences. Proceedings of the 58th Annual Meeting of the</p><p>    Association for Computational Linguistics, 2020.</p><p>-   Nag S., Kale M., Lakshminarasimhan V., Singhavi S. Incorporating</p><p>    bilingual dictionaries for low resource semi-supervised neural</p><p>    machine translation. Proceedings of ICLR 2019.</p><p>-   Hu J., Xia M., Neubig G., Carbonell J. Domain Adaptation of Neural</p><p>    Machine Translation by Lexicon Induction. Proceedings of the 57th</p><p>    Annual Meeting of the Association for Computational Linguistics,</p><p>    2019.</p><p>-   Chu C., Wang R. A Survey of Domain Adaptation for Machine</p><p>    Translation. Journal of Information Processing, Vol.28, 2020.</p><p>-   Servan C., Crego J., Senellart J. Adaptation incrémentale de</p><p>    modèles de traduction neuronaux. Actres de la 24ème Conférence sur</p><p>    le Traitement Automatique des Langues Naturelles (TALN), 2017.</p><p></p><p>Conditions sur les candidatures et Profil recherché:</p><p>Niveau demandé: Master 2, Ingénieur</p><p>Durée : 4-6 mois</p><p>Rémunération : entre 700 ¤ et 1300 ¤ selon la formation</p><p>Compétences requises :</p><p>-   environnement de travail : linux</p><p>-   maîtrise de langages de programmation : Python, C++, Java</p><p>-   expérience avec une bibliothèque de type Tensorflow, PyTorch, etc.</p><p>-   notion de base en apprentissage automatique et en réseaux de</p><p>    neurones</p><p>-   notions de base en traitement automatique des langues.</p><p></p><p>Modalité de dépôt de candidature :</p><p>Les candidatures (CV + Lettre de motivation) sont à envoyer le plus rapidement possible à Nasredine Semmar (nasredine.semmar@cea.fr).</p><p></p><p>Contacts pour plus d'information :</p><p>Nasredine SEMMAR,</p><p>Email: nasredine.semmar@cea.fr,</p><p>Tél: +33 (0)1 69 08 01 46</p><p></p>
</body>
</html>
        